{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7b5580",
   "metadata": {},
   "source": [
    "# Loading the HST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd9ffa",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649c48a",
   "metadata": {},
   "source": [
    "Coming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95058fa4",
   "metadata": {},
   "source": [
    "## The code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d99955",
   "metadata": {},
   "source": [
    "The code written below uses functions in ```src/calculations.py```. It is capable of looking for variations in the entire dataset (e.g. it is capable of running over each HST visit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8049c3d0",
   "metadata": {},
   "source": [
    "### Import the standard routines and load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9992dea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository home directory: /home/pas/science/exocomets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json, sys, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, cm\n",
    "\n",
    "# get the path of the current directory\n",
    "path = os.getcwd()\n",
    "home = os.path.dirname(path)\n",
    "\n",
    "# Print the repository home directory\n",
    "print(\"Repository home directory:\",home)\n",
    "\n",
    "# Add the src folder to the system path\n",
    "sys.path.append(home+'/src')\n",
    "\n",
    "# Import the python functions from src\n",
    "from calculations import Calc, Model, Stats\n",
    "\n",
    "# We shorten the functions name to make it easier to call the required a functions\n",
    "c   = Calc()\n",
    "m   = Model()\n",
    "s   = Stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514c62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing parameters from a json file.\n",
    "with open(home+'/params.json') as param_file:    \n",
    "   param = json.load(param_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86dcde6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the data directories we are using. To see what directories this is open params.json.\n",
    "datadirs = param[\"datadirs\"]\n",
    "\n",
    "# We select part A which is the red end of the spectrum (the other part being B, which is the blue end)\n",
    "part     = param[\"BetaPictoris\"][\"part\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b303a",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bdb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data used for this analysis:\n",
      "\n",
      " data/2017-04-23/\n",
      "\tAVM shift: 0.0\" \tEXP: 526s, \tDate: 2017-04-22, Time: 23:36:06 UTC\n",
      "\tAVM shift: 0.0\" \tEXP: 526s, \tDate: 2017-04-22, Time: 23:48:03 UTC\n",
      "\tAVM shift: 0.0\" \tEXP: 526s, \tDate: 2017-04-23, Time: 00:00:00 UTC\n",
      "\tAVM shift: 0.0\" \tEXP: 526s, \tDate: 2017-04-23, Time: 00:11:57 UTC\n",
      "\tAVM shift: -1.25\" \tEXP: 664s, \tDate: 2017-04-23, Time: 00:31:55 UTC\n",
      "\tAVM shift: -1.25\" \tEXP: 664s, \tDate: 2017-04-23, Time: 00:45:32 UTC\n",
      "\tAVM shift: -1.25\" \tEXP: 664s, \tDate: 2017-04-23, Time: 00:59:09 UTC\n",
      "\tAVM shift: -1.25\" \tEXP: 664s, \tDate: 2017-04-23, Time: 01:12:46 UTC\n",
      "\tAVM shift: 1.1\" \tEXP: 664s, \tDate: 2017-04-23, Time: 02:07:24 UTC\n",
      "\tAVM shift: 1.1\" \tEXP: 664s, \tDate: 2017-04-23, Time: 02:21:01 UTC\n",
      "\tAVM shift: 1.1\" \tEXP: 664s, \tDate: 2017-04-23, Time: 02:34:38 UTC\n",
      "\tAVM shift: 1.1\" \tEXP: 664s, \tDate: 2017-04-23, Time: 02:48:15 UTC\n",
      "\n",
      " data/2017-06-10/\n",
      "\tAVM shift: 0.0\" \tEXP: 526s, \tDate: 2017-06-10, Time: 20:02:24 UTC\n",
      "\tAVM shift: 0.0\" \tEXP: 526s, \tDate: 2017-06-10, Time: 20:14:21 UTC\n",
      "\tAVM shift: 0.0\" \tEXP: 526s, \tDate: 2017-06-10, Time: 20:26:18 UTC\n",
      "\tAVM shift: 0.0\" \tEXP: 526s, \tDate: 2017-06-10, Time: 20:38:15 UTC\n",
      "\tAVM shift: -1.1\" \tEXP: 664s, \tDate: 2017-06-10, Time: 21:29:04 UTC\n",
      "\tAVM shift: -1.1\" \tEXP: 664s, \tDate: 2017-06-10, Time: 21:42:41 UTC\n",
      "\tAVM shift: -1.1\" \tEXP: 664s, \tDate: 2017-06-10, Time: 21:56:18 UTC\n",
      "\tAVM shift: -1.1\" \tEXP: 664s, \tDate: 2017-06-10, Time: 22:09:55 UTC\n",
      "\tAVM shift: 1.1\" \tEXP: 664s, \tDate: 2017-06-10, Time: 23:04:21 UTC\n",
      "\tAVM shift: 1.1\" \tEXP: 664s, \tDate: 2017-06-10, Time: 23:17:58 UTC\n",
      "\tAVM shift: 1.1\" \tEXP: 664s, \tDate: 2017-06-10, Time: 23:31:35 UTC\n",
      "\tAVM shift: 1.1\" \tEXP: 664s, \tDate: 2017-06-10, Time: 23:45:12 UTC\n"
     ]
    }
   ],
   "source": [
    "D = []\n",
    "\n",
    "print(\"Data used for this analysis:\")\n",
    "\n",
    "for i in sorted(datadirs):\n",
    "    if param[\"filenames\"][\"split_files\"] == 'yes':\n",
    "        if datadirs[i][5:-1] in [\"2017-04-23\",\"2017-06-10\",\"2017-08-04\",\"2017-10-21\",\"2017-11-26\",\"2018-03-17\",\"2018-05-09\"]:\n",
    "            print(\"\\n\",datadirs[i])\n",
    "            D.append(c.GetData(param, home+'/'+datadirs[i]))\n",
    "    else:\n",
    "        print(\"\\n\",datadirs[i][5:-1])\n",
    "        D.append(c.GetData(param, home+'/'+datadirs[i]))\n",
    "    \n",
    "# We save the data\n",
    "np.savez(home+'/data/D_'+part+'.npz', D, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca09f99",
   "metadata": {},
   "source": [
    "### We now normalise, shift and re-normalise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into the multidimentional array D\n",
    "D = c.LoadData(home+'/data/D_'+part+'.npz')\n",
    "\n",
    "# Normalise the data\n",
    "Dn = c.NormSpec(param, D)\n",
    "\n",
    "# Shift the data relative to the first spectrum of each visit\n",
    "Dns = c.ShiftSpec(param, Dn)\n",
    "\n",
    "# Re normalise the data\n",
    "Dnsn = c.NormSpec(param, Dns)\n",
    "\n",
    "# We save the normalised and shifted data\n",
    "np.savez(home+'/data/Dnsn_'+part+'.npz', Dns, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18fc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
